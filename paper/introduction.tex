\section{Introduction}

We humans exhibit a remarkable ability to learn new concepts fast and efficiently. This ability is in stark contrast with conventional supervised machine learning, which is data-hungry and requires a plethora of data points to develop an effective model. Meta-learning reframes the traditional machine learning problem, allowing machine learning models to learn new problems by utilising only a few examples. Humans have an innate capability to \textit{learn how to learn}, and bridging this gap between human and machine learning is particularly beneficial in domains where data availability or acquisition is difficult, such as the drug-discovery domain. The drug-discovery process's primary goal is identifying and developing active compounds that exhibit therapeutic effects against biological targets. The drug-discovery process comes with exorbitant costs and resource expenditure, which can exceed one billion dollars and take up to 15 years to complete \cite{hughes2011principles}.

Moreover, data is also expensive and difficult to acquire, as this requires testing of numerous compounds both \textit{in-vitro} and, much later, \textit{in-vivo}. Even upon identification of leads, attrition rates are high as the compound usually fails for other reasons such as poor absorption, distribution, metabolism, excretion, or toxicology (ADMET) characteristics \cite{waring2015analysis}. It is difficult to predict such characteristics of the candidate molecule when only a small amount of related biological data is available. Therefore, the hist discovery, lead identification, and optimisation steps in drug discovery are essentially a low-data problem \cite{altae2017low}. In recent years, the computer vision domain saw successful applications and advancements for low-data machine learning \cite{koch2015siamese, vinyals2016matching, snell2017prototypical, sung2018learning}. Few-shot learning relieves the burden of collecting large-scale labelled data and makes learning rare cases possible \cite{wang2020generalizing}. 

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{img/tox21-metalearning.png}
    \caption{2-way 3-shot few-shot classification. Training a meta-learner on experimental assays and generalising for an unseen assay in the Tox-21 dataset.}
    \label{fig:tox21metalearning}
\end{figure}

Building on this notion, we explore few-shot learning to address the low-data problem for hit discovery, lead identification and optimisation. The ability of a machine learning model to learn new concepts fast with just a few training examples is invaluable for this domain, where data on active compounds is scarce. Meta-learning aims to achieve generalising capabilities for previously unseen environments during training time. In few-shot classification, a meta-learning paradigm, we train models using a variety of training tasks and optimise classification performance over a distribution of tasks, including unseen ones. Learning consists of a series of episodes, each consisting of an \textit{N}-way \textit{K}-shot classification task, effectively simulating the conditions at testing time. $N$ refers to the number of classes we include per task, while $K$ refers to the number of molecules we sample for each class to make up the support set \cite{snell2017prototypical}. For this study, few-shot learning refers to training with as little as one example per class, referred to as one-shot learning \cite{koch2015siamese, vinyals2016matching}, to a maximum of ten examples per class. During test time, a small support set is sampled from new, previously unseen targets, and the model uses these few data points to generalise query molecules' activity against this new target \cite{vinyals2016matching}. Figure~\ref{fig:tox21metalearning} shows an example of a typical meta-learning scenario on the Tox21 dataset \citep{huang2016tox21challenge}, where data from a set of assays reserved for training are used to train a model. This model is subsequently used to generalise for a previously unseen assay using only a small support set from this new assay. We highlight that few-shot learning in this problem domain differs from other domains, such as computer vision, where a model is trained to recognise new classes. For example, given a few images of a lion, a class unseen during training, as the support set, the model must generalise for new images of a lion. In the domain under study, the challenge is to train a model that can generalise for the behaviour of molecules in experimental assays which are related but not identical to the assays in the training collection, using only a small support set from these new experimental assays. The molecules used during testing can thus be previously seen during training, but only in the context of their activity for different, but related experimental assays. Given a few molecules from new experimental assays, can the model predict the activity of molecules in this new assay using molecular data for different but related targets as training data?

Molecules are complex structures consisting of atoms and bonds which must be somehow represented in computational space. The classical notation of compounds is the empirical formula such as $C_3H_7NO_2$. However, this can refer to alanine, sarcosine, or lactamide as empirical formulae hold no information on a molecule's topology. Molecular representations such as Extended-Connectivity Fingerprints (ECFP) \cite{rogers2010extended}, and graph convolution learned embeddings \cite{duvenaud2015convolutional} embed more information than the empirical formula on the properties of the molecule. This study mainly explores using graphs as embeddings for the low-data machine learning networks.

A graph $G$ is a natural representation of a molecule, where nodes and edges represent atoms and bonds, respectively. When representing molecules, the set of vertices or nodes \textit{V} intuitively refers to atoms within a molecule, while the set of edges \textit{E} refers to the bonds that connect two atoms; such that $\mathcal{G}=(\mathcal{V}, \mathcal{E})$. Graphs are 2D objects, so spatial properties of a molecule, such as bond angles and chirality, are not inherent to the data object but are instead encoded as node or edge attributes \cite{david2020molecular}. Embeddings of molecular graphs, augmented with atom feature information, can be learned using graph convolutional networks (GCNs). Selected properties such as atomic number, atom type, charge, and valences, among others, may be encoded in a node feature vector. \citet{wu2018moleculenet} report that learned embeddings could be of benefit over topological molecular representations such as ECFP.

In this study, we explore the application of several few-shot learning architectures including, in chronological order, Siamese Networks \citep{koch2015siamese}, Matching Networks \citep{vinyals2016matching}, Prototypical Networks \citep{snell2017prototypical}, and Relation Networks \citep{sung2018learning}. This group of architectures all fall under the umbrella of metric-based meta-learning. In our study, we embed molecule representations using GCNs, and then use or learn a distance function over these embeddings. Effectively, metric-based learners seek to learn a relationship between the input embeddings in the task space. 

\section{Related Work}

Several successful research undertakings have exploited the low-data learning paradigm, especially in the computer-vision domain \cite{koch2015siamese, vinyals2016matching, snell2017prototypical, sung2018learning}. Learning from only a few examples is especially important in domains with a paucity of data. This inaccessibility could be attributed to privacy, safety, or ethical issues and other issues such as the time, resources and exorbitant costs associated with data acquisition. Learning with low-data can lead to less expensive data gathering, and reduced computational cost for learning \cite{wang2020generalizing}.

Building on past work in the metric-based meta-learning sphere \cite{vinyals2016matching}, \citet{altae2017low} introduce a deep-learning architecture for few-shot learning in drug discovery, in which they propose the iterative refinement long short-term memory (IterRefLSTM). IterRefLSTM builds on the Matching Networks \cite{vinyals2016matching} by introducing iterative refinement of embeddings using Long-Short Term Memory (LSTM) networks. In our research, we build on the work by \citet{altae2017low} and extend it by applying other successful few-shot learning approaches explored for other domains, such as the computer-vision domain. The authors employ Graph Convolutional Networks (GCN) to learn molecular embeddings, which are then fed into the low-data architectures for classification.

\subsection{Graph Convolutional Networks}

Molecules must be represented in computational space before processing them using few-shot machine learning techniques. \citet{wu2018moleculenet} report that graph-based models outperform conventional machine learning models on most datasets, suggesting that a learned embedding is advantageous over other molecular representations. Building on this rationale, we opt for graph learned molecular representations to embed the input molecules in this study. 

Graph Convolutional Networks (GCNs) may be used to learn molecular representations \cite{jiang2021could}. Embeddings learned through neural networks afford the construction of automated features rather than fixed fingerprints. GCNs transform small molecules into real-valued vector representations, which are an effective way of processing small molecules via deep neural networks \cite{gomez2018automatic}. \citet{duvenaud2015convolutional} report that using a differentiable method reduces collisions of substructures, and the learned embedding can be optimised to contain relevant features such as biological activity and substructure information.

If the graph object is our input signal, we can apply a set of operators to approximate the function we are attempting to learn. \citet{bronstein2021geometric} propose four key building blocks for deep learning on graphs, which include linear set equivariant layers, non-linear functions, local pooling layers, and set invariant layers. For graphs, the nodes $v$ are found on a domain $\Omega$ such that $v \in \Omega$. The nodes in $\Omega$ are stored in a feature space $C$, such that $C = \mathbb{R}^k$. Using a set of feature functions $X(\Omega, C)$, we can transform the feature space of the nodes in our domain. 

In the equivariant layer $B$, we can take the nodes in our domain and apply a function that transforms the features of the nodes such that $X(\Omega, C) \rightarrow X(\Omega', C')$. Equivariance allows for a function $g$ to be applied before or after this layer, such that $B(g.x) = g.B(x)$. The non-linear activation functions can be applied element-wise on the features of the nodes in a graph, such that $(\sigma(x))(v) = \sigma(x(v))$. Local pooling layers can be used to apply coarsening to the graph such that $X(\Omega, C) \rightarrow X(\Omega', C)$, in which we can reduce the number of nodes in our domain such that $\Omega' \subseteq \Omega$. Finally, we have the invariant layer $Z$, which can also be referred to as a global pooling layer, in which $X(\Omega, C) \rightarrow y$, which satisfies the invariant condition such that $Z(g.x) = Z(x)$ \citep{bronstein2021geometric}. Figure \ref{fig:neuralgraphfingerprint} illustrates an example of a GCN to learn a molecular embedding.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\linewidth]{img/graph_mol_embedding.png}
    \caption[Learned Embedding through a GCN]{A typical pipeline for representing molecules using a learned embedding function, which can be processed further using feedforward neural networks as shown. Reproduced from \citet{jiang2021could}.}
    \label{fig:neuralgraphfingerprint}
  \end{figure}

\subsection{Metric-based Few-Shot Learning}

The success of a few-shot learning model for metric-based meta-learning is dependent on the effectiveness of a kernel $k_\theta$, which measures the similarity between data samples ${x..x_i}$ from a support set $S$ (see Equation \ref{kernel}) using a metric or distance function. The techniques employed in this study, excluding the benchmark model, use the support and query embeddings generated from the GCNs to learn the kernel function. We explore four few-shot learning models in this study, which are presented in the Methodology section. These include Siamese Networks, Matching Networks (upon which the state-of-the-art is developed), Prototypical Networks and Relation Networks. The two latter networks are new approaches for this problem domain and are mostly inspired by the computer vision domain.

\begin{equation}
    \label{kernel}
    P_\theta(y \vert \mathbf{x}, S) = \sum_{(\mathbf{x}_i, y_i) \in S} k_\theta(\mathbf{x}, \mathbf{x}_i)y_i
\end{equation}

\subsubsection{Siamese Networks}

Siamese networks \citep{koch2015siamese} are composed of two identical networks with shared weights and parameters, taking in a pair of data samples (molecules) as inputs. The distance between outputs from each component in the pair of networks is calculated to learn their relationship. The following is the process, repeated for all training tasks, employed for learning a classifier using Siamese Networks.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\linewidth]{img/high-level siamese.png}
    \caption[High-level schematic of Siamese network]{High-level schematic of a Siamese network for the molecular network.}
    \label{fig:siamesenetarchi}
\end{figure}

\begin{enumerate}
    \item Generate a list of all possible pairs between training data. If both data samples in the pair have the same target, the pair's label is set to one and zero if otherwise.
    \item Create a twin network using the GCN architecture to embed two molecular graph inputs into latent space.
    \item Calculate the L1 distance between the molecule embeddings. 
    \item The distance between the two embeddings is passed through a linear feedforward layer, followed by a sigmoid function to output the probability that the two molecules belong to the same class.
    \item The binary cross-entropy loss is calculated and backpropagated through the network.
\end{enumerate}

\subsubsection{Matching Networks}

The Matching Networks architecture builds on Siamese Networks. However, instead of learning a metric function over data pairs, the classifier learns how to define a probability distribution of output labels from query examples using a support set $S$. The classifier outputs a sum of attention-weighted labels from the support set to predict the similarity between the query and the support set samples. We use the same embedding function for the support and query sets to compute the molecular embeddings. Subsequently, the cosine similarity of pairs of data points between the support and query sets is computed, which is then normalised by a softmax function. The attention mechanism $a$ in $\hat{y} = \sum_{i=1}^{n} a(\hat{x}, x_i)y_i$ specifies how similar $\hat{x}$ is to each example $x$ in $S$.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\linewidth]{img/matching_networks.png}
    \caption[Matching Networks Architecture]{Matching Networks Architecture. Reproduced from \citet{vinyals2016matching}.}
    \label{fig:matchingnets}
\end{figure}

Figure~\ref{fig:matchingnets} illustrates the Matching Nets architecture. Embedding functions $f$ and $g$ are Convolutional Neural Networks (CNNs) \citep{lecun1995convolutional}, potentially being identical to each other, which project the inputs to the feature space. \citet{vinyals2016matching} also propose full context embedding functions, which take as input the whole support set with the element $x_i$, thus resulting in \( g(x_i, S) \). Full context embeddings effectively modify how the element is embedded with respect to the whole support set $S$. A bidirectional LSTM is used to encode $x_i$ in the context of the support set. Finally, the attention mechanism $a$, is the classifier which takes a softmax over the cosine distance of the embeddings. As proposed in \citet{vinyals2016matching}, fully contextual embeddings (FCE) are used in our implementation. Taking single data points to learn an embedding function limits the ability to embed the molecules effectively into latent space. Therefore, a bidirectional long-short term memory (LSTM) is used, which takes the whole support set as input to adjust the embedding based on the other support samples. $g_\theta(x_i, S)$ encodes $x_i$, a data sample from the support set, in the context of the whole support set $S$. The LSTM transforms our support set embeddings by adding the forward and backward activations to the original support image embeddings. Subsequently, $f_\theta(x, S)$, encodes the query sample $x$ and trains the LSTM with read attention over the support set. The hidden state is updated over ten processing ``read'' steps until, eventually, the hidden state is equivalent to the aforementioned $f_\theta(x, S)$. The hidden state and the output from the attention function are updated in each iteration. The cross-entropy loss is computed for each query prediction whilst training the model using stochastic gradient descent.

\subsubsection{Prototypical Networks}

Prototypical Networks \citep{snell2017prototypical} have similarities to Matching Networks, but instead of considering the individual support set embeddings, the mean vector of the embeddings (referred to as the \textit{prototype}) for each class within the support set is taken. Another improvement \citet{snell2017prototypical} make over Matching Networks is using Euclidean distance rather than the cosine distance to calculate the distances to classify the query (refer to Figure~\ref{fig:protonets}). In order to classify query data samples, the softmax of the Euclidean distance's inverse between each query and each prototype is taken. The negative log-likelihood is used to train the network through stochastic gradient descent

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\linewidth]{img/protonets.png}
    \caption{Few-shot learning in Prototypical Networks, where prototypes \textbf{$c_k$} are taken as the mean of embedded support examples for each class. Reproduced from \citet{snell2017prototypical}.}
    \label{fig:protonets}
\end{figure}

\subsubsection{Relation Networks}

\citet{sung2018learning} present the Relation Network, a framework for few-shot learning, which could also be extended to zero-shot learning. The Relation Network learns a non-linear distance metric to compare support and query examples. Unlike previously mentioned networks, this network uses a feedforward neural network to learn a distance function in feature space. After embedding the support and query examples using an embedding function, each query example is concatenated with each feature map from the support set. The relationship between the queries and the different classes within the support set is captured by passing the feature map concatenations through a feed-forward neural network $g_\theta([x_i, x_j])$ to predict a relation score. The output class can be inferred from this relation score vector. $[\cdot,\cdot]$ is the concatenation between each support set data sample $x_i$ and the query data samples $x_j$. The Mean Squared Error (MSE) is used as the loss function, as proposed in the original paper. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\linewidth]{img/relation-nets.png}
    \caption[Relation Networks]{Few-shot learning scenario in Relation Networks for a 5-way 1-shot learning task with one query as an example. Reproduced from \citet{sung2018learning}.}
    \label{fig:relationnets}
\end{figure}

\subsection{Iterative Refinement LSTM}

\citet{altae2017low} build on meta-learning concepts by training machine learning models on molecular data from a set of experimental assay targets (from the Tox21, SIDER, and MUV datasets) reserved for training. The model is then used to generalise for the activity of molecules in new, previously unseen experimental assays using only a small support set from these new assays. These test assays are related but not identical to the ones reserved for training. The number of molecules sampled for each class in the support set ranges from one to a maximum of ten molecules. The support and query molecules are embedded in their work using a graph convolutional network. Bond information and distinction between bond types was not considered in their study. We note that the \textit{pool} layers do not coarsen the graphs but only apply a max function over neighbouring nodes.

\citet{altae2017low} propose the iterative refinement long-short term memory (IterRefLSTM) to further process the resulting embeddings in a few-shot machine learning pipeline. In IterRefLSTMs two embedding functions $f(\dot|S)$ and $g(\dot|S)$ are developed simultaneously. Therefore, the query embedding is built iteratively with that of the support set, using information from the two sets to enhance both the support and query embeddings. Once the embeddings have been iteratively refined, the authors apply a metric-based function to classify the queries using the support set embeddings. To emulate the Matching Networks, the authors use the Cosine distance to compare embeddings. Figure \ref{fig:schematiconeshotdrug} illustrates a one-shot learning scenario encapsulating the concepts mentioned earlier.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\linewidth]{img/pandeschematic.png}
    \caption[Schematic of one-shot learning in drug discovery]{Schematic of one-shot learning in drug discovery based on the Matching Network \citep{vinyals2016matching} architecture. Reproduced from \citet{altae2017low}.}
    \label{fig:schematiconeshotdrug}
\end{figure}

Their work is evaluated on the Tox21, the Side Effect Resource (SIDER) \citep{kuhn2016sider}, and MUV datasets\citep{rohrer2009maximum}. For every dataset, a subset of the targets is reserved for training and the rest for testing. Training is carried out as explained in the Matching Networks paper, in which training conditions match those at test time \citep{vinyals2016matching}. The authors use a Random Forest (RF) with 100 decision trees as a machine learning baseline model. They also utilise a conventional Graph Convolutional Networks (GCN) \citep{kipf2016semi} as an additional baseline model, which is trained using only a small support set from the test targets. They then experiment with Siamese Networks \citep{koch2015siamese}, Matching Networks \citep{vinyals2016matching}, and an adaptation of the Matching Networks by applying the iterative refinement concepts explained earlier.

The authors utilise ROC-AUC scores to report the performance of the models. Considering the extreme imbalance of the data in the utilised datasets, favouring the negative (inactive/decoy) class, we note that the PR-AUC score would be a more appropriate evaluation measure. PR-AUC is based on the relationship between precision and recall, providing a clearer picture of how the model performs when predicting the \textit{positive} (active) class in the data. Correctly predicting the ``active'' class is of significant importance in virtual screening.

On the Tox21 and SIDER datasets, their proposed machine learning architecture achieves good ROC-AUC performance. The mean score for 10-shot learning on the median held-out task on Tox21 achieves a score of $0.823 \pm 0.002$, while for one-shot learning, the model achieves a mean score of $0.827 \pm 0.001$. The reasons why one-shot learning achieved better performance than 10-shot learning is uncertain, as we expect the model to perform better with larger support sets. However, this might be attributed to variance in the data between experiments. On MUV data, the baseline machine learning models performed few-shot learning. The authors report that this is due to MUV data being maximally informative; therefore, structural similarity cannot be utilised to generalise activity prediction. The authors open-sourced their models in the DeepChem library\citep{ramsundar2019deep}. However, the implementations are now outdated and we were unable to train and test these models using the provided scripts. However, we study the open-sourced implementation and the respective details in the original literature to reproduce their work successfully.
